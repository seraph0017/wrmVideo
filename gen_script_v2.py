#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
gen_script_v2.py - å¢å¼ºç‰ˆè„šæœ¬ç”Ÿæˆå™¨

åŸºäºgen_script.pyçš„å¢å¼ºç‰ˆæœ¬ï¼Œæ–°å¢åŠŸèƒ½ï¼š
1. è‡ªåŠ¨ç« èŠ‚è´¨é‡éªŒè¯
2. ä¸è¾¾æ ‡ç« èŠ‚è‡ªåŠ¨é‡æ–°ç”Ÿæˆ
3. æ”¯æŒæŒ‡å®šç”Ÿæˆå‰Nä¸ªç« èŠ‚
4. å¢å¼ºçš„éªŒè¯å’Œé‡è¯•æœºåˆ¶

ä½¿ç”¨æ–¹æ³•:
    python gen_script_v2.py novel.txt --output data/001 --chapters 5
    python gen_script_v2.py novel.txt --output data/001 --validate-only
"""

import os
import sys
import re
import json
import argparse
import tempfile
import zipfile
import shutil
import time
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from volcenginesdkarkruntime import Ark
from jinja2 import Environment, FileSystemLoader
try:
    import rarfile
except ImportError:
    rarfile = None

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from config.prompt_config import prompt_config, SCRIPT_CONFIG
from config.config import ARK_CONFIG

class ContentFilter:
    """
    å†…å®¹è¿‡æ»¤å™¨ï¼Œç”¨äºæ£€æµ‹å’Œæ›¿æ¢è¿ç¦è¯æ±‡å’Œéœ²éª¨æ–‡æ¡ˆ
    """
    
    def __init__(self):
        # è¿ç¦è¯æ±‡åˆ—è¡¨ï¼ˆå¤§å¹…æ”¾æ¾ - ä»…ä¿ç•™æç«¯æ•æ„Ÿå†…å®¹ï¼‰
        self.forbidden_words = {
            'åŒä¿®', 'é‡‡è¡¥', 'å¸ç²¾', 'å¸ç²¾æ°”', 'ä¹±æ‘¸', 'ä¹±åŠ¨', 
            'çˆ†æµ†', 'å¤§å®è´', 'è‰²æƒ…', 'å·äºº', 'é¼ç‚‰', 
            'æ˜¥è¯', 'åªšè¯', 'å‚¬æƒ…', 'å…å¸', 'æ¯’å“', 
            'ä¸ŠåºŠ', 'å¼ºæš´', 'æ€§æ¬²'
        }
        
        # è”æƒ³æ€§è¯æ±‡ï¼ˆå¤§å¹…æ”¾æ¾ - ä»…ä¿ç•™æç«¯ä¸å½“å†…å®¹ï¼‰
        self.suggestive_words = {
            'ç”Ÿå‘½å¤§å’Œè°', 'æ¬²æœ›ä¸Šå¤´', 'æˆ¿é—´äº’åŠ¨', 
            'å‰å‡¸åç¿˜', 'ä½ ä¾¬æˆ‘ä¾¬', 'å¿å¿æˆ‘æˆ‘'
        }
        
        # ç¦ç”¨å¥å¼æ¨¡å¼ï¼ˆå¤§å¹…æ”¾æ¾ - ä»…ä¿ç•™æç«¯ä¸å½“å¥å¼ï¼‰
        self.forbidden_patterns = [
            r'æˆ‘å’Œ.*ä¸€èµ·ç¡', r'.*æ²¾äº†.*èº«å­', 
            r'.*æŠšæ‘¸.*', r'.*çˆ±æŠš.*', r'.*ä½“é¦™.*'
        ]
        
        # æ•æ„Ÿè¯æ›¿æ¢æ˜ å°„
        self.word_replacements = {
            'ç½ªçŠ¯': 'å«Œç–‘äºº',
            'é€šç¼‰çŠ¯': 'TJ',
            'è­¦å¯Ÿ': 'jc',
            'ç›‘ç‹±': 'ç‰¢ç‹±',
            'é—ä½“': 'YT',
            'æ­»': 'S',
            'ä¸ŠåŠ': 'SD',
            'è‡ªæ€': 'ZS',
            'è·³æ¥¼': 'TL',
            'å°¸ä½“': 'ST',
            'å›æˆ¿ç¡è§‰': 'å›æˆ¿ä¼‘æ¯',
            'ç¡è§‰': 'ä¼‘æ¯'
        }
    
    def check_content(self, content: str) -> Tuple[bool, List[str]]:
        """
        æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ…å«è¿ç¦è¯æ±‡æˆ–éœ²éª¨æ–‡æ¡ˆ
        
        Args:
            content: è¦æ£€æŸ¥çš„å†…å®¹
            
        Returns:
            Tuple[bool, List[str]]: (æ˜¯å¦é€šè¿‡æ£€æŸ¥, å‘ç°çš„é—®é¢˜åˆ—è¡¨)
        """
        issues = []
        
        # æ£€æŸ¥è¿ç¦è¯æ±‡
        for word in self.forbidden_words:
            if word in content:
                issues.append(f"å‘ç°è¿ç¦è¯æ±‡: {word}")
        
        # æ£€æŸ¥è”æƒ³æ€§è¯æ±‡
        for word in self.suggestive_words:
            if word in content:
                issues.append(f"å‘ç°è”æƒ³æ€§è¯æ±‡: {word}")
        
        # æ£€æŸ¥ç¦ç”¨å¥å¼
        import re
        for pattern in self.forbidden_patterns:
            matches = re.findall(pattern, content)
            if matches:
                issues.append(f"å‘ç°ç¦ç”¨å¥å¼: {matches}")
        
        return len(issues) == 0, issues
    
    def filter_content(self, content: str) -> str:
        """
        è¿‡æ»¤å†…å®¹ï¼Œæ›¿æ¢æ•æ„Ÿè¯æ±‡
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            str: è¿‡æ»¤åçš„å†…å®¹
        """
        filtered_content = content
        
        # æ‰§è¡Œè¯æ±‡æ›¿æ¢
        for original, replacement in self.word_replacements.items():
            filtered_content = filtered_content.replace(original, replacement)
        
        # ç§»é™¤è¿ç¦è¯æ±‡ï¼ˆç®€å•æ›¿æ¢ä¸ºç©ºæˆ–åŒä¹‰è¯ï¼‰
        word_substitutions = {
            'æ‹¥æŠ±': 'ç›¸ä¼´',
            'æ¸©æŸ”': 'å’Œå–„',
            'æ¸©çƒ­': 'æ¸©æš–',
            'ç›®å…‰': 'è§†çº¿',
            'æ¬²æœ›': 'æ„¿æœ›',
            'äº’åŠ¨': 'äº¤æµ',
            'è¯±æƒ‘': 'å¸å¼•',
            'æ€€é‡Œ': 'èº«è¾¹',
            'å¤§è…¿': 'è…¿éƒ¨',
            'æŠ±èµ·': 'æ‰¶èµ·',
            'å§¿åŠ¿': 'åŠ¨ä½œ'
        }
        
        for word, substitute in word_substitutions.items():
            filtered_content = filtered_content.replace(word, substitute)
        
        # ç§»é™¤å…¶ä»–ä¸¥é‡è¿ç¦è¯æ±‡
        serious_forbidden = {
            'åŒä¿®', 'é‡‡è¡¥', 'å¸ç²¾', 'å¸ç²¾æ°”', 'ä¹±æ‘¸', 'ä¹±åŠ¨', 'èµ¤è£¸è£¸', 
            'æœä¾', 'çˆ†æµ†', 'åºŠä¸Š', 'å¤§å®è´', 'å‹¾å¼•', 'è‰²æƒ…', 'å·äºº', 
            'é¼ç‚‰', 'æ˜¥è¯', 'åªšè¯', 'è½¯åºŠ', 'ä¸è¢œ', 'å‚¬æƒ…', 'å…å¸', 
            'æ¯’å“', 'ä¸ŠåºŠ', 'å¼ºæš´', 'æ€§æ¬²'
        }
        
        for word in serious_forbidden:
            filtered_content = filtered_content.replace(word, '')
        
        # æ¸…ç†å¤šä½™ç©ºæ ¼
        import re
        filtered_content = re.sub(r'\s+', ' ', filtered_content)
        filtered_content = filtered_content.strip()
        
        return filtered_content

class ScriptGeneratorV2:
    """
    å¢å¼ºç‰ˆè„šæœ¬ç”Ÿæˆå™¨
    
    æ–°å¢åŠŸèƒ½ï¼š
    - è‡ªåŠ¨ç« èŠ‚è´¨é‡éªŒè¯
    - ä¸è¾¾æ ‡ç« èŠ‚é‡æ–°ç”Ÿæˆ
    - æ”¯æŒæŒ‡å®šç”Ÿæˆç« èŠ‚æ•°é‡
    - å¢å¼ºçš„éªŒè¯æœºåˆ¶
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–è„šæœ¬ç”Ÿæˆå™¨
        
        Args:
            api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸æä¾›åˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
        """
        self.api_key = api_key or ARK_CONFIG.get('api_key')
        if not self.api_key:
            raise ValueError("APIå¯†é’¥æœªé…ç½®")
        
        self.client = Ark(api_key=self.api_key)
        self.model = ARK_CONFIG.get('model', 'doubao-seed-1-6-flash-250615')
        self.lock = threading.Lock()
        print(f"ä½¿ç”¨æ¨¡å‹: {self.model}")
        
        # åˆå§‹åŒ–å†…å®¹è¿‡æ»¤å™¨
        self.content_filter = ContentFilter()
        
        # éªŒè¯é…ç½®ï¼ˆå¤§å¹…æ”¾æ¾é™åˆ¶ï¼‰
        self.validation_config = {
            'min_length': 500,   # å¤§å¹…é™ä½æœ€å°å­—æ•°è¦æ±‚
            'max_length': 3000,  # è¿›ä¸€æ­¥å¢åŠ æœ€å¤§å­—æ•°é™åˆ¶
            'max_retries': 8,    # å¤§å¹…å¢åŠ é‡è¯•æ¬¡æ•°
            'quality_threshold': 0.4  # å¤§å¹…é™ä½è´¨é‡é˜ˆå€¼
        }
    
    def read_novel_file(self, file_path: str) -> str:
        """
        è¯»å–å°è¯´æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œç¼–ç 
        
        Args:
            file_path: å°è¯´æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: å°è¯´å†…å®¹
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")
        
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext == '.zip':
            return self._read_zip_file(file_path)
        elif file_ext == '.rar':
            return self._read_rar_file(file_path)
        else:
            # æ™®é€šæ–‡æœ¬æ–‡ä»¶
            encodings = ['utf-8', 'gbk', 'gb2312', 'utf-16']
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    print(f"æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è¯»å–æ–‡ä»¶")
                    return content
                except UnicodeDecodeError:
                    continue
            
            raise ValueError(f"æ— æ³•è§£ç æ–‡ä»¶ï¼š{file_path}")
    
    def _read_zip_file(self, zip_path: str) -> str:
        """è¯»å–ZIPæ–‡ä»¶ä¸­çš„æ–‡æœ¬å†…å®¹"""
        with zipfile.ZipFile(zip_path, 'r') as zip_file:
            file_list = zip_file.namelist()
            txt_files = [f for f in file_list if f.lower().endswith('.txt')]
            
            if not txt_files:
                raise ValueError("ZIPæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°.txtæ–‡ä»¶")
            
            # é€‰æ‹©ç¬¬ä¸€ä¸ªtxtæ–‡ä»¶
            txt_file = txt_files[0]
            print(f"ä»ZIPæ–‡ä»¶ä¸­è¯»å–ï¼š{txt_file}")
            
            with zip_file.open(txt_file) as f:
                file_content = f.read()
            
            return self._decode_file_content(file_content, txt_file)
    
    def _read_rar_file(self, rar_path: str) -> str:
        """è¯»å–RARæ–‡ä»¶ä¸­çš„æ–‡æœ¬å†…å®¹"""
        if rarfile is None:
            raise ImportError("éœ€è¦å®‰è£…rarfileåº“æ¥å¤„ç†RARæ–‡ä»¶")
        
        with rarfile.RarFile(rar_path) as rar_file:
            file_list = rar_file.namelist()
            txt_files = [f for f in file_list if f.lower().endswith('.txt')]
            
            if not txt_files:
                raise ValueError("RARæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°.txtæ–‡ä»¶")
            
            txt_file = txt_files[0]
            print(f"ä»RARæ–‡ä»¶ä¸­è¯»å–ï¼š{txt_file}")
            
            with rar_file.open(txt_file) as f:
                file_content = f.read()
            
            return self._decode_file_content(file_content, txt_file)
    
    def _decode_file_content(self, file_content: bytes, filename: str) -> str:
        """è§£ç æ–‡ä»¶å†…å®¹"""
        encodings = ['utf-8', 'gbk', 'gb2312', 'utf-16']
        
        for encoding in encodings:
            try:
                content = file_content.decode(encoding)
                print(f"æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è§£ç æ–‡ä»¶ {filename}")
                return content
            except UnicodeDecodeError:
                continue
        
        raise ValueError(f"æ— æ³•è§£ç æ–‡ä»¶å†…å®¹ï¼š{filename}")
    
    def split_novel_into_chapters(self, novel_content: str, target_chapters: int = 50) -> List[str]:
        """
        å°†å°è¯´å†…å®¹åˆ†å‰²æˆæŒ‡å®šæ•°é‡çš„ç« èŠ‚
        
        Args:
            novel_content: å°è¯´å†…å®¹
            target_chapters: ç›®æ ‡ç« èŠ‚æ•°é‡
            
        Returns:
            List[str]: ç« èŠ‚å†…å®¹åˆ—è¡¨
        """
        # æ¸…ç†æ–‡æœ¬
        novel_content = re.sub(r'\n\s*\n', '\n\n', novel_content)
        novel_content = novel_content.strip()
        
        # å°è¯•æŒ‰ç« èŠ‚æ ‡é¢˜åˆ†å‰²
        chapter_patterns = [
            r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+ç« [^\n]*',
            r'ç¬¬[\d]+ç« [^\n]*',
            r'Chapter\s*\d+[^\n]*',
            r'ç« èŠ‚\s*\d+[^\n]*'
        ]
        
        chapters = []
        for pattern in chapter_patterns:
            matches = list(re.finditer(pattern, novel_content, re.IGNORECASE))
            if len(matches) >= 2:
                for i, match in enumerate(matches):
                    start = match.start()
                    end = matches[i + 1].start() if i + 1 < len(matches) else len(novel_content)
                    chapter_content = novel_content[start:end].strip()
                    if len(chapter_content) > 100:
                        chapters.append(chapter_content)
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç« èŠ‚æ ‡é¢˜ï¼ŒæŒ‰é•¿åº¦åˆ†å‰²
        if not chapters:
            total_length = len(novel_content)
            chunk_size = total_length // target_chapters
            
            for i in range(target_chapters):
                start = i * chunk_size
                end = (i + 1) * chunk_size if i < target_chapters - 1 else total_length
                chapter_content = novel_content[start:end].strip()
                if chapter_content:
                    chapters.append(chapter_content)
        
        # å¦‚æœç« èŠ‚æ•°é‡è¶…è¿‡ç›®æ ‡ï¼Œåˆå¹¶è¾ƒçŸ­çš„ç« èŠ‚
        if len(chapters) > target_chapters:
            merged_chapters = []
            current_chapter = ""
            target_length = sum(len(ch) for ch in chapters) // target_chapters
            
            for chapter in chapters:
                if len(current_chapter) < target_length:
                    current_chapter += "\n\n" + chapter if current_chapter else chapter
                else:
                    merged_chapters.append(current_chapter)
                    current_chapter = chapter
            
            if current_chapter:
                if merged_chapters:
                    merged_chapters[-1] += "\n\n" + current_chapter
                else:
                    merged_chapters.append(current_chapter)
            
            chapters = merged_chapters[:target_chapters]
        
        print(f"æˆåŠŸåˆ†å‰²ä¸º {len(chapters)} ä¸ªç« èŠ‚")
        return chapters
    
    def generate_chapter_narration(self, chapter_content: str, chapter_num: int, total_chapters: int) -> str:
        """
        ä¸ºå•ä¸ªç« èŠ‚ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ
        
        Args:
            chapter_content: ç« èŠ‚å†…å®¹
            chapter_num: ç« èŠ‚ç¼–å·
            total_chapters: æ€»ç« èŠ‚æ•°
            
        Returns:
            str: ç”Ÿæˆçš„è§£è¯´æ–‡æ¡ˆ
        """
        try:
            # ä½¿ç”¨Jinja2æ¨¡æ¿ç”Ÿæˆæç¤ºè¯
            template_path = os.path.join(project_root, 'chapter_narration_prompt.j2')
            
            if not os.path.exists(template_path):
                raise FileNotFoundError(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨ï¼š{template_path}")
            
            # è®¾ç½®Jinja2ç¯å¢ƒ
            env = Environment(loader=FileSystemLoader(project_root))
            template = env.get_template('chapter_narration_prompt.j2')
            
            # æ¸²æŸ“æ¨¡æ¿
            prompt = template.render(
                chapter_num=chapter_num,
                total_chapters=total_chapters,
                chapter_content=chapter_content
            )
            
            # è°ƒç”¨APIç”Ÿæˆ
            with self.lock:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=32*1024,  # å¢åŠ tokené™åˆ¶ä»¥é€‚åº”æ›´å¤æ‚çš„è¾“å‡ºæ ¼å¼
                    temperature=0.7
                )
            
            narration = response.choices[0].message.content.strip()
            return narration
            
        except Exception as e:
            print(f"ç”Ÿæˆç¬¬{chapter_num}ç« è§£è¯´æ—¶å‡ºé”™ï¼š{e}")
            return ""
    
    def validate_narration_content(self, narration: str, min_length: int = 1300, max_length: int = 1700) -> Tuple[bool, str]:
        """
        éªŒè¯è§£è¯´å†…å®¹çš„è´¨é‡ï¼ˆæ£€æŸ¥å­—æ•°ã€è‡ªåŠ¨ä¿®å¤XMLæ ‡ç­¾é—­åˆã€ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾ã€å†…å®¹å®¡æŸ¥ï¼‰
        
        Args:
            narration: å®Œæ•´çš„narrationå†…å®¹
            min_length: è§£è¯´æ–‡æœ¬çš„æœ€å°é•¿åº¦
            max_length: è§£è¯´æ–‡æœ¬çš„æœ€å¤§é•¿åº¦
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯æˆ–ä¿®æ­£åçš„å†…å®¹)
        """
        if not narration or not narration.strip():
            return False, "è§£è¯´å†…å®¹ä¸ºç©º"
        
        narration = narration.strip()
        
        # æ£€æŸ¥å¹¶ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾
        cleaned_narration = self._remove_unwanted_tags(narration)
        
        # å†…å®¹å®¡æŸ¥ - æ£€æŸ¥è¿ç¦è¯æ±‡å’Œéœ²éª¨æ–‡æ¡ˆï¼ˆä»…è­¦å‘Šæ¨¡å¼ï¼‰
        try:
            is_content_safe, content_issues = self.content_filter.check_content(cleaned_narration)
            if not is_content_safe:
                print(f"è­¦å‘Šï¼šå†…å®¹å®¡æŸ¥å‘ç°é—®é¢˜: {'; '.join(content_issues)}")
                # å°è¯•è‡ªåŠ¨è¿‡æ»¤å†…å®¹
                filtered_narration = self.content_filter.filter_content(cleaned_narration)
                print("å·²è‡ªåŠ¨è¿‡æ»¤æ•æ„Ÿå†…å®¹")
                cleaned_narration = filtered_narration
                
                # å†æ¬¡æ£€æŸ¥è¿‡æ»¤åçš„å†…å®¹ï¼ˆä»…è­¦å‘Šï¼Œä¸é˜»æ–­ï¼‰
                is_filtered_safe, filtered_issues = self.content_filter.check_content(cleaned_narration)
                if not is_filtered_safe:
                    print(f"è­¦å‘Šï¼šè¿‡æ»¤åä»å­˜åœ¨é—®é¢˜: {'; '.join(filtered_issues)}ï¼Œä½†ç»§ç»­ç”Ÿæˆ")
        except Exception as e:
            print(f"è­¦å‘Šï¼šå†…å®¹å®¡æŸ¥è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸ï¼Œè·³è¿‡å®¡æŸ¥ - {e}")
        
        # æå–æ‰€æœ‰<è§£è¯´å†…å®¹>æ ‡ç­¾å†…çš„æ–‡æœ¬è¿›è¡Œå­—æ•°ç»Ÿè®¡ï¼ˆæ–°æ ¼å¼ï¼šæ¯ä¸ªç‰¹å†™åŒ…å«ç‹¬ç«‹è§£è¯´ï¼‰
        import re
        explanation_pattern = r'<è§£è¯´å†…å®¹>(.*?)</è§£è¯´å†…å®¹>'
        explanation_matches = re.findall(explanation_pattern, cleaned_narration, re.DOTALL)
        
        if not explanation_matches:
            return False, "æœªæ‰¾åˆ°è§£è¯´å†…å®¹æ ‡ç­¾"
        
        # è®¡ç®—æ‰€æœ‰è§£è¯´å†…å®¹çš„æ€»å­—æ•°ï¼ˆæ–°æ ¼å¼ï¼š30ä¸ªç‰¹å†™çš„è§£è¯´å†…å®¹ï¼‰
        total_explanation_text = ''.join(explanation_matches)
        explanation_length = len(total_explanation_text.strip())
        
        # éªŒè¯ç‰¹å†™æ•°é‡ï¼ˆ10ä¸ªåˆ†é•œå„3ä¸ªç‰¹å†™=30ä¸ªè§£è¯´å†…å®¹ï¼‰
        expected_explanations = 30
        if len(explanation_matches) != expected_explanations:
            print(f"è­¦å‘Šï¼šè§£è¯´å†…å®¹æ•°é‡ä¸æ­£ç¡®ï¼ŒæœŸæœ›{expected_explanations}ä¸ªï¼Œå®é™…{len(explanation_matches)}ä¸ª")
        
        if explanation_length < min_length:
            return False, f"è§£è¯´æ–‡æœ¬é•¿åº¦ä¸è¶³ï¼Œå½“å‰{explanation_length}å­—ï¼Œæœ€å°‘éœ€è¦{min_length}å­—"
        
        if explanation_length > max_length:
            return False, f"è§£è¯´æ–‡æœ¬è¿‡é•¿ï¼Œå½“å‰{explanation_length}å­—ï¼Œæœ€å¤šå…è®¸{max_length}å­—"
        
        # éªŒè¯å›¾ç‰‡ç‰¹å†™æ˜¯å¦ä¸ºå•äººç”»é¢ï¼ˆä»…æç¤ºï¼Œä¸å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼‰
        try:
            single_person_valid, single_person_error = self._validate_single_person_closeups(cleaned_narration)
            if not single_person_valid:
                print(f"è­¦å‘Šï¼šæ£€æµ‹åˆ°å¤šäººç‰¹å†™æè¿° - {single_person_error}")
                # ä¸è¿”å›é”™è¯¯ï¼Œä»…è®°å½•è­¦å‘Š
        except Exception as e:
            print(f"è­¦å‘Šï¼šç‰¹å†™éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸ï¼Œè·³è¿‡éªŒè¯ - {e}")
            # éªŒè¯å¼‚å¸¸ä¸å½±å“ç”Ÿæˆæµç¨‹
        
        # è§’è‰²ä¸€è‡´æ€§éªŒè¯å·²ç§»é™¤
        
        # è‡ªåŠ¨ä¿®å¤XMLæ ‡ç­¾é—­åˆ
        fixed_narration = self._fix_xml_tags(cleaned_narration)
        
        return True, fixed_narration
    
    def _remove_unwanted_tags(self, content: str) -> str:
        """
        ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            str: ç§»é™¤ä¸éœ€è¦æ ‡ç­¾åçš„å†…å®¹
        """
        import re
        
        # å®šä¹‰éœ€è¦ç§»é™¤çš„æ ‡ç­¾åˆ—è¡¨
        unwanted_tags = [
            'è§’è‰²ç¼–å·', 'è§’è‰²ç±»å‹', 'é£æ ¼', 'æ–‡åŒ–', 'æ°”è´¨'
        ]
        
        cleaned_content = content
        removed_tags = []
        
        # ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾åŠå…¶å†…å®¹
        for tag in unwanted_tags:
            # åŒ¹é…å¼€å§‹å’Œç»“æŸæ ‡ç­¾ä¹‹é—´çš„å†…å®¹
            pattern = f'<{tag}>.*?</{tag}>'
            matches = re.findall(pattern, cleaned_content, re.DOTALL)
            if matches:
                removed_tags.extend([tag] * len(matches))
                cleaned_content = re.sub(pattern, '', cleaned_content, flags=re.DOTALL)
            
            # ç§»é™¤å•ç‹¬çš„å¼€å§‹æ ‡ç­¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            single_tag_pattern = f'<{tag}>'
            if re.search(single_tag_pattern, cleaned_content):
                removed_tags.append(f'{tag}(å•æ ‡ç­¾)')
                cleaned_content = re.sub(single_tag_pattern, '', cleaned_content)
            
            # ç§»é™¤å•ç‹¬çš„ç»“æŸæ ‡ç­¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            end_tag_pattern = f'</{tag}>'
            if re.search(end_tag_pattern, cleaned_content):
                removed_tags.append(f'{tag}(ç»“æŸæ ‡ç­¾)')
                cleaned_content = re.sub(end_tag_pattern, '', cleaned_content)
        
        # å¦‚æœç§»é™¤äº†æ ‡ç­¾ï¼Œè¾“å‡ºæ—¥å¿—
        if removed_tags:
            print(f"è‡ªåŠ¨ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾ï¼š{', '.join(removed_tags)}")
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        cleaned_content = re.sub(r'\n\s*\n', '\n', cleaned_content)
        
        return cleaned_content.strip()
    
    def _fix_xml_tags(self, content: str) -> str:
        """
        è‡ªåŠ¨ä¿®å¤XMLæ ‡ç­¾é—­åˆé—®é¢˜
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            str: ä¿®å¤åçš„å†…å®¹
        """
        import re
        
        # æŸ¥æ‰¾æ‰€æœ‰å¼€å§‹æ ‡ç­¾
        open_tags = re.findall(r'<([^/\s>]+)[^>]*>', content)
        # æŸ¥æ‰¾æ‰€æœ‰ç»“æŸæ ‡ç­¾
        close_tags = re.findall(r'</([^\s>]+)>', content)
        
        # æ‰¾å‡ºæœªé—­åˆçš„æ ‡ç­¾
        unclosed_tags = []
        for tag in open_tags:
            if tag not in close_tags:
                unclosed_tags.append(tag)
        
        # åœ¨å†…å®¹æœ«å°¾æ·»åŠ ç¼ºå¤±çš„é—­åˆæ ‡ç­¾
        fixed_content = content
        for tag in reversed(unclosed_tags):  # åå‘æ·»åŠ ï¼Œä¿æŒåµŒå¥—ç»“æ„
            if f'</{tag}>' not in fixed_content:
                fixed_content += f'</{tag}>'
                print(f"è‡ªåŠ¨ä¿®å¤ï¼šæ·»åŠ ç¼ºå¤±çš„é—­åˆæ ‡ç­¾ </{tag}>")
        
        return fixed_content
    
    def _validate_single_person_closeups(self, content: str) -> Tuple[bool, str]:
        """
        éªŒè¯å›¾ç‰‡ç‰¹å†™æ˜¯å¦ä¸ºå•äººç”»é¢ï¼Œå¹¶æ£€æŸ¥ç‰¹å†™ä¸è§£è¯´å†…å®¹çš„å¯¹åº”å…³ç³»
        
        Args:
            content: è§£è¯´å†…å®¹
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        import re
        
        # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡promptå†…å®¹
        prompt_pattern = r'<å›¾ç‰‡prompt>(.*?)</å›¾ç‰‡prompt>'
        prompt_matches = re.findall(prompt_pattern, content, re.DOTALL)
        
        if not prompt_matches:
            return False, "æœªæ‰¾åˆ°å›¾ç‰‡promptæ ‡ç­¾"
        
        # æ£€æŸ¥æ¯ä¸ªå›¾ç‰‡promptæ˜¯å¦åŒ…å«å¤šäººæè¿°
        multi_person_keywords = [
            'ä¸¤äºº', 'ä¸‰äºº', 'å¤šäºº', 'ä¸€ç¾¤äºº', 'ä¼—äºº', 'å¤§å®¶', 'ä»–ä»¬', 'å¥¹ä»¬',
            'ä¸¤ä¸ªäºº', 'ä¸‰ä¸ªäºº', 'å‡ ä¸ªäºº', 'æ‰€æœ‰äºº', 'äººç¾¤', 'ä¸€å¯¹', 'å¤«å¦»',
            'æƒ…ä¾£', 'æœ‹å‹ä»¬', 'åŒä¼´', 'ä¼™ä¼´ä»¬', 'å…„å¼Ÿ', 'å§å¦¹', 'çˆ¶å­',
            'æ¯å¥³', 'å¸ˆå¾’', 'ä¸»ä»†', 'å›è‡£', 'åŒæ—¶', 'ä¸€èµ·', 'å…±åŒ',
            'ç›¸è§†', 'å¯¹è§†', 'é¢å¯¹é¢', 'å¹¶è‚©', 'æºæ‰‹', 'æ‹¥æŠ±', 'ä¾å'
        ]
        
        # æå–æ‰€æœ‰è§£è¯´å†…å®¹ç”¨äºå¯¹åº”å…³ç³»éªŒè¯
        explanation_pattern = r'<è§£è¯´å†…å®¹>(.*?)</è§£è¯´å†…å®¹>'
        explanation_matches = re.findall(explanation_pattern, content, re.DOTALL)
        
        # æŒ‰åˆ†é•œç»„ç»‡ç‰¹å†™å’Œè§£è¯´å†…å®¹
        scene_pattern = r'<åˆ†é•œ(\d+)>(.*?)</åˆ†é•œ\d+>'
        scene_matches = re.findall(scene_pattern, content, re.DOTALL)
        
        for scene_num, scene_content in scene_matches:
            # æå–è¯¥åˆ†é•œçš„è§£è¯´å†…å®¹
            scene_explanation_match = re.search(r'<è§£è¯´å†…å®¹>(.*?)</è§£è¯´å†…å®¹>', scene_content, re.DOTALL)
            if not scene_explanation_match:
                continue
                
            scene_explanation = scene_explanation_match.group(1).strip()
            
            # æå–è¯¥åˆ†é•œçš„æ‰€æœ‰ç‰¹å†™
            scene_prompts = re.findall(r'<å›¾ç‰‡prompt>(.*?)</å›¾ç‰‡prompt>', scene_content, re.DOTALL)
            
            if len(scene_prompts) != 3:
                return False, f"åˆ†é•œ{scene_num}çš„ç‰¹å†™æ•°é‡ä¸æ­£ç¡®ï¼Œåº”è¯¥æœ‰3ä¸ªç‰¹å†™ï¼Œå®é™…æœ‰{len(scene_prompts)}ä¸ª"
            
            # éªŒè¯æ¯ä¸ªç‰¹å†™çš„å†…å®¹
            for prompt_idx, prompt in enumerate(scene_prompts, 1):
                prompt_text = prompt.strip().lower()
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šäººå…³é”®è¯
                for keyword in multi_person_keywords:
                    if keyword in prompt_text:
                        return False, f"åˆ†é•œ{scene_num}ç¬¬{prompt_idx}ä¸ªç‰¹å†™åŒ…å«å¤šäººæè¿°å…³é”®è¯ï¼š'{keyword}'ï¼Œæ¯ä¸ªç‰¹å†™å¿…é¡»åªæœ‰ä¸€ä¸ªäººç‰©"
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—+äººçš„æ¨¡å¼
                number_person_pattern = r'[äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[ä¸ª]?äºº'
                if re.search(number_person_pattern, prompt_text):
                    match = re.search(number_person_pattern, prompt_text)
                    return False, f"åˆ†é•œ{scene_num}ç¬¬{prompt_idx}ä¸ªç‰¹å†™åŒ…å«å¤šäººæ•°é‡æè¿°ï¼š'{match.group()}'ï¼Œæ¯ä¸ªç‰¹å†™å¿…é¡»åªæœ‰ä¸€ä¸ªäººç‰©"
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤æ•°äººç§°ä»£è¯
                plural_pronouns = ['ä»–ä»¬çš„', 'å¥¹ä»¬çš„', 'å¤§å®¶çš„', 'ä¼—äººçš„', 'äººä»¬çš„']
                for pronoun in plural_pronouns:
                    if pronoun in prompt_text:
                        return False, f"åˆ†é•œ{scene_num}ç¬¬{prompt_idx}ä¸ªç‰¹å†™åŒ…å«å¤æ•°äººç§°ä»£è¯ï¼š'{pronoun}'ï¼Œæ¯ä¸ªç‰¹å†™å¿…é¡»åªæœ‰ä¸€ä¸ªäººç‰©"
            
            # éªŒè¯ç‰¹å†™ä¸è§£è¯´å†…å®¹çš„å¯¹åº”å…³ç³»ï¼ˆåŸºç¡€æ£€æŸ¥ï¼‰
            self._validate_closeup_content_correspondence(scene_num, scene_explanation, scene_prompts)
        
        return True, ""
    
    def _validate_closeup_content_correspondence(self, scene_num: str, explanation: str, prompts: List[str]) -> None:
        """
        éªŒè¯ç‰¹å†™ä¸è§£è¯´å†…å®¹çš„å¯¹åº”å…³ç³»ï¼ˆåŸºç¡€æ£€æŸ¥ï¼‰
        
        Args:
            scene_num: åˆ†é•œç¼–å·
            explanation: è§£è¯´å†…å®¹
            prompts: å›¾ç‰‡ç‰¹å†™æè¿°åˆ—è¡¨
        """
        # å°†è§£è¯´å†…å®¹åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†
        explanation_length = len(explanation)
        part1_end = explanation_length // 3
        part2_end = explanation_length * 2 // 3
        
        explanation_part1 = explanation[:part1_end]
        explanation_part2 = explanation[part1_end:part2_end]
        explanation_part3 = explanation[part2_end:]
        
        # æå–å…³é”®è¯è¿›è¡ŒåŸºç¡€åŒ¹é…éªŒè¯
        parts = [explanation_part1, explanation_part2, explanation_part3]
        
        for i, (part, prompt) in enumerate(zip(parts, prompts), 1):
            # æå–è§£è¯´å†…å®¹ä¸­çš„å…³é”®åŠ¨ä½œè¯å’Œæƒ…æ„Ÿè¯
            action_keywords = self._extract_action_keywords(part)
            emotion_keywords = self._extract_emotion_keywords(part)
            
            # æ£€æŸ¥ç‰¹å†™æè¿°æ˜¯å¦åŒ…å«ç›¸åº”çš„å…³é”®è¯
            prompt_lower = prompt.lower()
            
            # è®°å½•åŒ¹é…æƒ…å†µï¼ˆä»…ä½œä¸ºè­¦å‘Šï¼Œä¸å¼ºåˆ¶å¤±è´¥ï¼‰
            action_matches = any(keyword in prompt_lower for keyword in action_keywords)
            emotion_matches = any(keyword in prompt_lower for keyword in emotion_keywords)
            
            if not action_matches and action_keywords:
                print(f"è­¦å‘Šï¼šåˆ†é•œ{scene_num}ç‰¹å†™{i}å¯èƒ½ä¸è§£è¯´å†…å®¹ç¬¬{i}éƒ¨åˆ†çš„åŠ¨ä½œæè¿°ä¸å¤ŸåŒ¹é…")
            
            if not emotion_matches and emotion_keywords:
                print(f"è­¦å‘Šï¼šåˆ†é•œ{scene_num}ç‰¹å†™{i}å¯èƒ½ä¸è§£è¯´å†…å®¹ç¬¬{i}éƒ¨åˆ†çš„æƒ…æ„Ÿæè¿°ä¸å¤ŸåŒ¹é…")
    
    def _extract_action_keywords(self, text: str) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–åŠ¨ä½œå…³é”®è¯
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            
        Returns:
            List[str]: åŠ¨ä½œå…³é”®è¯åˆ—è¡¨
        """
        action_words = [
            'èµ°', 'è·‘', 'ç«™', 'å', 'èºº', 'è·³', 'é£', 'æ¸¸', 'çˆ¬', 'æ»š',
            'çœ‹', 'å¬', 'è¯´', 'ç¬‘', 'å“­', 'å–Š', 'å«', 'å”±', 'è¯»', 'å†™',
            'æ‹¿', 'æ”¾', 'æŠ“', 'æ¡', 'æ¨', 'æ‹‰', 'æ‰“', 'è¸¢', 'æ‰”', 'æ¥',
            'å¼€', 'å…³', 'è¿›', 'å‡º', 'ä¸Š', 'ä¸‹', 'å·¦', 'å³', 'å‰', 'å',
            'è½¬èº«', 'å›å¤´', 'ç‚¹å¤´', 'æ‘‡å¤´', 'æŒ¥æ‰‹', 'é èº¬', 'èµ·èº«', 'åä¸‹'
        ]
        
        found_keywords = []
        for word in action_words:
            if word in text:
                found_keywords.append(word)
        
        return found_keywords
    
    def _extract_emotion_keywords(self, text: str) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–æƒ…æ„Ÿå…³é”®è¯
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            
        Returns:
            List[str]: æƒ…æ„Ÿå…³é”®è¯åˆ—è¡¨
        """
        emotion_words = [
            'é«˜å…´', 'å¿«ä¹', 'å…´å¥‹', 'æ¿€åŠ¨', 'å¼€å¿ƒ', 'æ„‰å¿«', 'æ¬£å–œ', 'å–œæ‚¦',
            'æ‚²ä¼¤', 'éš¾è¿‡', 'ä¼¤å¿ƒ', 'ç—›è‹¦', 'å¿§æ„', 'æ²®ä¸§', 'å¤±è½', 'ç»æœ›',
            'æ„¤æ€’', 'ç”Ÿæ°”', 'æ¼æ€’', 'æš´æ€’', 'æ„¤æ…¨', 'æ¼ç«', 'æ°”æ„¤', 'æ€’ç«',
            'å®³æ€•', 'ææƒ§', 'ç´§å¼ ', 'æ‹…å¿ƒ', 'ç„¦è™‘', 'ä¸å®‰', 'æƒŠæ…Œ', 'ææ…Œ',
            'æƒŠè®¶', 'éœ‡æƒŠ', 'åƒæƒŠ', 'è¯§å¼‚', 'æ„å¤–', 'æƒŠå¥‡', 'æƒŠæ„•', 'é”™æ„•',
            'å¹³é™', 'å†·é™', 'æ·¡å®š', 'ä»å®¹', 'é•‡å®š', 'å®‰è¯¦', 'å®é™', 'ç¥¥å’Œ',
            'ä¸¥è‚ƒ', 'è®¤çœŸ', 'ä¸“æ³¨', 'å‡é‡', 'åº„é‡', 'è‚ƒç©†', 'å¨ä¸¥', 'åº„ä¸¥',
            'æ¸©å’Œ', 'å’Œå–„', 'æ…ˆç¥¥', 'äº²åˆ‡', 'å‹å–„', 'å’Œè”¼', 'æ¸©æŸ”', 'æŸ”å’Œ'
        ]
        
        found_keywords = []
        for word in emotion_words:
            if word in text:
                found_keywords.append(word)
        
        return found_keywords
    
    # _validate_character_consistency å‡½æ•°å·²ç§»é™¤
    
    def audit_and_filter_narration(self, narration: str, chapter_num: int) -> Tuple[bool, str]:
        """
        å¯¹ç”Ÿæˆçš„è§£è¯´å†…å®¹è¿›è¡Œå®¡æŸ¥å’Œè¿‡æ»¤
        
        Args:
            narration: åŸå§‹è§£è¯´å†…å®¹
            chapter_num: ç« èŠ‚ç¼–å·
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦é€šè¿‡å®¡æŸ¥, å®¡æŸ¥åçš„å†…å®¹æˆ–é”™è¯¯ä¿¡æ¯)
        """
        try:
            # æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ…å«è¿ç¦è¯æ±‡
            is_safe, issues = self.content_filter.check_content(narration)
            
            if not is_safe:
                print(f"ç¬¬{chapter_num}ç« å†…å®¹å®¡æŸ¥å‘ç°é—®é¢˜:")
                for issue in issues:
                    print(f"  - {issue}")
                
                # å°è¯•è‡ªåŠ¨è¿‡æ»¤
                filtered_content = self.content_filter.filter_content(narration)
                print(f"ç¬¬{chapter_num}ç« å·²è‡ªåŠ¨è¿‡æ»¤æ•æ„Ÿå†…å®¹")
                
                # å†æ¬¡æ£€æŸ¥è¿‡æ»¤åçš„å†…å®¹
                is_filtered_safe, remaining_issues = self.content_filter.check_content(filtered_content)
                
                if not is_filtered_safe:
                    print(f"ç¬¬{chapter_num}ç« è¿‡æ»¤åä»å­˜åœ¨é—®é¢˜:")
                    for issue in remaining_issues:
                        print(f"  - {issue}")
                    return False, f"å†…å®¹åŒ…å«æ— æ³•è‡ªåŠ¨è¿‡æ»¤çš„è¿ç¦å†…å®¹: {'; '.join(remaining_issues)}"
                
                return True, filtered_content
            else:
                print(f"ç¬¬{chapter_num}ç« å†…å®¹å®¡æŸ¥é€šè¿‡")
                return True, narration
                
        except Exception as e:
            print(f"ç¬¬{chapter_num}ç« å†…å®¹å®¡æŸ¥æ—¶å‡ºé”™: {e}")
            return False, f"å†…å®¹å®¡æŸ¥å¤±è´¥: {e}"
    
    def generate_chapter_narration_with_retry(self, chapter_content: str, chapter_num: int, 
                                            total_chapters: int, max_retries: int = 3) -> str:
        """
        å¸¦é‡è¯•æœºåˆ¶çš„ç« èŠ‚è§£è¯´ç”Ÿæˆï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            chapter_content: ç« èŠ‚å†…å®¹
            chapter_num: ç« èŠ‚ç¼–å·
            total_chapters: æ€»ç« èŠ‚æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            str: ç”Ÿæˆçš„è§£è¯´æ–‡æ¡ˆ
        """
        for attempt in range(max_retries):
            try:
                print(f"æ­£åœ¨ç”Ÿæˆç¬¬{chapter_num}ç« è§£è¯´æ–‡æ¡ˆï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰...")
                
                narration = self.generate_chapter_narration(chapter_content, chapter_num, total_chapters)
                
                if narration:
                    # é¦–å…ˆè¿›è¡Œå†…å®¹å®¡æŸ¥å’Œè¿‡æ»¤
                    audit_passed, audit_result = self.audit_and_filter_narration(narration, chapter_num)
                    
                    if not audit_passed:
                        print(f"âœ— ç¬¬{chapter_num}ç« å†…å®¹å®¡æŸ¥å¤±è´¥ï¼š{audit_result}")
                        del narration
                        if attempt < max_retries - 1:
                            print(f"å°†è¿›è¡Œç¬¬ {attempt + 2} æ¬¡å°è¯•...")
                            time.sleep(2)
                        continue
                    
                    # ä½¿ç”¨å®¡æŸ¥åçš„å†…å®¹è¿›è¡ŒéªŒè¯
                    filtered_narration = audit_result
                    
                    # éªŒè¯å¹¶ä¿®å¤ç”Ÿæˆçš„å†…å®¹
                    is_valid, result = self.validate_narration_content(
                        filtered_narration, 
                        self.validation_config['min_length'], 
                        self.validation_config['max_length']
                    )
                    
                    if is_valid:
                        # resultæ˜¯ä¿®å¤åçš„å†…å®¹
                        final_narration = result
                        print(f"âœ“ ç¬¬{chapter_num}ç« è§£è¯´æ–‡æ¡ˆç”ŸæˆæˆåŠŸï¼ˆ{len(final_narration)}å­—ï¼Œå·²é€šè¿‡å†…å®¹å®¡æŸ¥ï¼‰")
                        # é‡Šæ”¾åŸå§‹narrationå†…å­˜
                        del narration
                        del filtered_narration
                        return final_narration
                    else:
                        # resultæ˜¯é”™è¯¯ä¿¡æ¯
                        print(f"âœ— ç¬¬{chapter_num}ç« è§£è¯´æ–‡æ¡ˆéªŒè¯å¤±è´¥ï¼š{result}")
                        # ç«‹å³é‡Šæ”¾å¤±è´¥çš„narrationå†…å­˜
                        del narration
                        del filtered_narration
                        if attempt < max_retries - 1:
                            print(f"å°†è¿›è¡Œç¬¬ {attempt + 2} æ¬¡å°è¯•...")
                            time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                else:
                    print(f"âœ— ç¬¬{chapter_num}ç« è§£è¯´æ–‡æ¡ˆç”Ÿæˆå¤±è´¥")
                    
            except Exception as e:
                print(f"ç”Ÿæˆç¬¬{chapter_num}ç« è§£è¯´æ—¶å‡ºé”™ï¼ˆå°è¯• {attempt + 1}ï¼‰ï¼š{e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
        
        print(f"âœ— ç¬¬{chapter_num}ç« è§£è¯´æ–‡æ¡ˆç”Ÿæˆæœ€ç»ˆå¤±è´¥")
        return ""
    
    def save_chapter(self, chapter_content: str, narration: str, chapter_num: int, output_dir: str) -> bool:
        """
        ä¿å­˜ç« èŠ‚å†…å®¹å’Œè§£è¯´æ–‡æ¡ˆï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            chapter_content: ç« èŠ‚åŸå§‹å†…å®¹
            narration: è§£è¯´æ–‡æ¡ˆ
            chapter_num: ç« èŠ‚ç¼–å·
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            chapter_dir = os.path.join(output_dir, f"chapter_{chapter_num:03d}")
            os.makedirs(chapter_dir, exist_ok=True)
            
            # ä¿å­˜åŸå§‹ç« èŠ‚å†…å®¹ï¼ˆç«‹å³å†™å…¥ï¼Œä¸ç¼“å­˜ï¼‰
            with open(os.path.join(chapter_dir, "original_content.txt"), 'w', encoding='utf-8') as f:
                f.write(chapter_content)
                f.flush()  # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº
            
            # ä¿å­˜è§£è¯´æ–‡æ¡ˆï¼ˆç«‹å³å†™å…¥ï¼Œä¸ç¼“å­˜ï¼‰
            with open(os.path.join(chapter_dir, "narration.txt"), 'w', encoding='utf-8') as f:
                f.write(narration)
                f.flush()  # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº
            
            print(f"âœ“ ç¬¬{chapter_num}ç« æ–‡ä»¶ä¿å­˜æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"ä¿å­˜ç¬¬{chapter_num}ç« æ—¶å‡ºé”™ï¼š{e}")
            return False
    
    def _force_garbage_collection(self):
        """
        å¼ºåˆ¶æ‰§è¡Œåƒåœ¾å›æ”¶ä»¥é‡Šæ”¾å†…å­˜
        """
        import gc
        gc.collect()
    
    def validate_existing_chapters(self, output_dir: str, chapter_range: Optional[Tuple[int, int]] = None) -> Tuple[List[int], List[int], List[int]]:
        """
        éªŒè¯å·²ç”Ÿæˆçš„ç« èŠ‚
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            chapter_range: ç« èŠ‚èŒƒå›´ (start, end)ï¼Œå¦‚æœä¸ºNoneåˆ™éªŒè¯æ‰€æœ‰ç« èŠ‚
            
        Returns:
            Tuple[List[int], List[int], List[int]]: (æ‰€æœ‰æ— æ•ˆç« èŠ‚, é•¿åº¦ä¸è¶³ç« èŠ‚, å…¶ä»–é—®é¢˜ç« èŠ‚)
        """
        all_invalid_chapters = []
        length_insufficient_chapters = []
        other_invalid_chapters = []
        
        if not os.path.exists(output_dir):
            print(f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼š{output_dir}")
            return all_invalid_chapters, length_insufficient_chapters, other_invalid_chapters
        
        # è·å–è¦éªŒè¯çš„ç« èŠ‚åˆ—è¡¨
        chapter_dirs = []
        for item in os.listdir(output_dir):
            if item.startswith('chapter_') and os.path.isdir(os.path.join(output_dir, item)):
                try:
                    chapter_num = int(item.split('_')[1])
                    if chapter_range is None or (chapter_range[0] <= chapter_num <= chapter_range[1]):
                        chapter_dirs.append((chapter_num, item))
                except ValueError:
                    continue
        
        chapter_dirs.sort(key=lambda x: x[0])  # æŒ‰ç« èŠ‚ç¼–å·æ’åº
        
        print(f"å¼€å§‹éªŒè¯ {len(chapter_dirs)} ä¸ªç« èŠ‚...")
        
        for chapter_num, chapter_dir_name in chapter_dirs:
            chapter_dir = os.path.join(output_dir, chapter_dir_name)
            narration_file = os.path.join(chapter_dir, 'narration.txt')
            
            validation_result = self._validate_single_chapter(chapter_num, chapter_dir, narration_file)
            if validation_result == 'length_insufficient':
                all_invalid_chapters.append(chapter_num)
                length_insufficient_chapters.append(chapter_num)
            elif validation_result == 'other_invalid':
                all_invalid_chapters.append(chapter_num)
                other_invalid_chapters.append(chapter_num)
        
        # è¾“å‡ºéªŒè¯ç»“æœ
        if all_invalid_chapters:
            print(f"\nå‘ç° {len(all_invalid_chapters)} ä¸ªéœ€è¦é‡æ–°ç”Ÿæˆçš„ç« èŠ‚ï¼š{all_invalid_chapters}")
            if length_insufficient_chapters:
                print(f"å…¶ä¸­ {len(length_insufficient_chapters)} ä¸ªç« èŠ‚é•¿åº¦ä¸è¶³ï¼š{length_insufficient_chapters}")
            if other_invalid_chapters:
                print(f"å…¶ä¸­ {len(other_invalid_chapters)} ä¸ªç« èŠ‚å­˜åœ¨å…¶ä»–é—®é¢˜ï¼š{other_invalid_chapters}")
        else:
            print("\nâœ“ æ‰€æœ‰ç« èŠ‚éªŒè¯é€šè¿‡")
        
        return all_invalid_chapters, length_insufficient_chapters, other_invalid_chapters
    
    def _validate_single_chapter(self, chapter_num: int, chapter_dir: str, narration_file: str) -> str:
        """
        éªŒè¯å•ä¸ªç« èŠ‚
        
        Args:
            chapter_num: ç« èŠ‚ç¼–å·
            chapter_dir: ç« èŠ‚ç›®å½•
            narration_file: narrationæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: 'valid', 'length_insufficient', 'other_invalid'
        """
        try:
            if not os.path.exists(narration_file):
                print(f"ç¬¬{chapter_num}ç« ç¼ºå°‘narration.txtæ–‡ä»¶")
                return 'other_invalid'
            
            with open(narration_file, 'r', encoding='utf-8') as f:
                narration_content = f.read()
            
            if not narration_content.strip():
                print(f"ç¬¬{chapter_num}ç« narrationæ–‡ä»¶ä¸ºç©º")
                return 'other_invalid'
            
            # éªŒè¯å¹¶ä¿®å¤å†…å®¹è´¨é‡
            is_valid, result = self.validate_narration_content(
                narration_content, 
                self.validation_config['min_length'], 
                self.validation_config['max_length']
            )
            
            if not is_valid:
                print(f"ç¬¬{chapter_num}ç« éªŒè¯å¤±è´¥ï¼š{result}")
                if "è¿‡çŸ­" in result:
                    return 'length_insufficient'
                else:
                    return 'other_invalid'
            else:
                # å¦‚æœå†…å®¹è¢«ä¿®å¤äº†ï¼Œä¿å­˜ä¿®å¤åçš„å†…å®¹
                if result != narration_content:
                    print(f"ç¬¬{chapter_num}ç« XMLæ ‡ç­¾å·²è‡ªåŠ¨ä¿®å¤ï¼Œæ­£åœ¨ä¿å­˜...")
                    with open(narration_file, 'w', encoding='utf-8') as f:
                        f.write(result)
                        f.flush()
                
                print(f"ç¬¬{chapter_num}ç« éªŒè¯é€šè¿‡")
                return 'valid'
                
        except Exception as e:
            print(f"éªŒè¯ç¬¬{chapter_num}ç« æ—¶å‡ºé”™ï¼š{e}")
            return 'other_invalid'
    
    def regenerate_invalid_chapters(self, output_dir: str, invalid_chapters: List[int]) -> bool:
        """
        é‡æ–°ç”Ÿæˆæ— æ•ˆçš„ç« èŠ‚
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            invalid_chapters: éœ€è¦é‡æ–°ç”Ÿæˆçš„ç« èŠ‚ç¼–å·åˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦å…¨éƒ¨é‡æ–°ç”ŸæˆæˆåŠŸ
        """
        if not invalid_chapters:
            return True
        
        print(f"\n=== å¼€å§‹é‡æ–°ç”Ÿæˆ {len(invalid_chapters)} ä¸ªæ— æ•ˆç« èŠ‚ ===")
        success_count = 0
        
        for chapter_num in invalid_chapters:
            chapter_dir = os.path.join(output_dir, f"chapter_{chapter_num:03d}")
            original_content_file = os.path.join(chapter_dir, "original_content.txt")
            
            if not os.path.exists(original_content_file):
                print(f"ç¬¬{chapter_num}ç« ç¼ºå°‘original_content.txtæ–‡ä»¶ï¼Œè·³è¿‡é‡æ–°ç”Ÿæˆ")
                continue
            
            try:
                with open(original_content_file, 'r', encoding='utf-8') as f:
                    chapter_content = f.read()
                
                print(f"\n--- é‡æ–°ç”Ÿæˆç¬¬ {chapter_num} ç«  ---")
                
                # ä½¿ç”¨å¸¦é‡è¯•çš„ç”Ÿæˆæ–¹æ³•
                narration = self.generate_chapter_narration_with_retry(
                    chapter_content, chapter_num, len(invalid_chapters), 
                    self.validation_config['max_retries']
                )
                
                if narration:
                    # ä¿å­˜é‡æ–°ç”Ÿæˆçš„è§£è¯´æ–‡æ¡ˆ
                    narration_file = os.path.join(chapter_dir, "narration.txt")
                    with open(narration_file, 'w', encoding='utf-8') as f:
                        f.write(narration)
                    
                    print(f"âœ“ ç¬¬{chapter_num}ç« é‡æ–°ç”ŸæˆæˆåŠŸ")
                    success_count += 1
                else:
                    print(f"âœ— ç¬¬{chapter_num}ç« é‡æ–°ç”Ÿæˆå¤±è´¥")
                    
            except Exception as e:
                print(f"é‡æ–°ç”Ÿæˆç¬¬{chapter_num}ç« æ—¶å‡ºé”™ï¼š{e}")
                continue
        
        print(f"\n=== é‡æ–°ç”Ÿæˆå®Œæˆ ===")
        print(f"æˆåŠŸé‡æ–°ç”Ÿæˆ {success_count}/{len(invalid_chapters)} ä¸ªç« èŠ‚")
        
        return success_count == len(invalid_chapters)
    
    def generate_script_from_novel(self, novel_file: str, output_dir: str, 
                                 target_chapters: int = 50, max_workers: int = 5,
                                 chapter_limit: Optional[int] = None) -> bool:
        """
        ä»å°è¯´æ–‡ä»¶ç”Ÿæˆè§£è¯´è„šæœ¬ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            novel_file: å°è¯´æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            target_chapters: ç›®æ ‡ç« èŠ‚æ•°é‡
            max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
            chapter_limit: é™åˆ¶ç”Ÿæˆçš„ç« èŠ‚æ•°é‡ï¼ˆå‰Nä¸ªç« èŠ‚ï¼‰
            
        Returns:
            bool: æ˜¯å¦ç”ŸæˆæˆåŠŸ
        """
        try:
            print(f"=== å¼€å§‹ç”Ÿæˆè§£è¯´è„šæœ¬ ===")
            print(f"å°è¯´æ–‡ä»¶ï¼š{novel_file}")
            print(f"è¾“å‡ºç›®å½•ï¼š{output_dir}")
            print(f"ç›®æ ‡ç« èŠ‚æ•°ï¼š{target_chapters}")
            if chapter_limit:
                print(f"é™åˆ¶ç”Ÿæˆï¼šå‰{chapter_limit}ä¸ªç« èŠ‚")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # è¯»å–å°è¯´å†…å®¹
            print("\n--- è¯»å–å°è¯´æ–‡ä»¶ ---")
            novel_content = self.read_novel_file(novel_file)
            print(f"å°è¯´æ€»é•¿åº¦ï¼š{len(novel_content)}å­—")
            
            # åˆ†å‰²ç« èŠ‚
            print("\n--- åˆ†å‰²ç« èŠ‚ ---")
            chapters = self.split_novel_into_chapters(novel_content, target_chapters)
            
            # åº”ç”¨ç« èŠ‚é™åˆ¶
            if chapter_limit and chapter_limit < len(chapters):
                chapters = chapters[:chapter_limit]
                print(f"åº”ç”¨ç« èŠ‚é™åˆ¶ï¼Œå®é™…ç”Ÿæˆï¼š{len(chapters)}ä¸ªç« èŠ‚")
            
            # é‡Šæ”¾å°è¯´åŸå§‹å†…å®¹å†…å­˜ï¼ˆå·²åˆ†å‰²å®Œæˆï¼‰
            del novel_content
            
            # ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ
            print(f"\n--- ç”Ÿæˆè§£è¯´æ–‡æ¡ˆï¼ˆ{len(chapters)}ä¸ªç« èŠ‚ï¼‰---")
            
            def generate_single_chapter(chapter_data):
                chapter_num, chapter_content = chapter_data
                try:
                    narration = self.generate_chapter_narration_with_retry(
                        chapter_content, chapter_num, len(chapters),
                        self.validation_config['max_retries']
                    )
                    
                    if narration:
                        success = self.save_chapter(chapter_content, narration, chapter_num, output_dir)
                        # ç«‹å³é‡Šæ”¾å†…å­˜
                        del narration
                        del chapter_content
                        return chapter_num, success
                    else:
                        # é‡Šæ”¾ç« èŠ‚å†…å®¹å†…å­˜
                        del chapter_content
                        return chapter_num, False
                except Exception as e:
                    print(f"å¤„ç†ç¬¬{chapter_num}ç« æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{e}")
                    # ç¡®ä¿åœ¨å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿé‡Šæ”¾å†…å­˜
                    if 'chapter_content' in locals():
                        del chapter_content
                    if 'narration' in locals():
                        del narration
                    return chapter_num, False
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ç”Ÿæˆï¼ˆå†…å­˜ä¼˜åŒ–ï¼šåˆ†æ‰¹å¤„ç†ï¼‰
            success_count = 0
            failed_chapters = []
            batch_size = min(max_workers * 2, 10)  # é™åˆ¶æ‰¹æ¬¡å¤§å°ä»¥æ§åˆ¶å†…å­˜ä½¿ç”¨
            
            for i in range(0, len(chapters), batch_size):
                batch_chapters = chapters[i:i + batch_size]
                chapter_data = [(i + j + 1, content) for j, content in enumerate(batch_chapters)]
                
                print(f"å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(chapters) + batch_size - 1)//batch_size}ï¼Œç« èŠ‚ {i+1}-{min(i+batch_size, len(chapters))}")
                
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_chapter = {executor.submit(generate_single_chapter, data): data[0] 
                                       for data in chapter_data}
                    
                    for future in as_completed(future_to_chapter):
                        chapter_num = future_to_chapter[future]
                        try:
                            result_chapter_num, success = future.result()
                            if success:
                                success_count += 1
                            else:
                                failed_chapters.append(result_chapter_num)
                        except Exception as e:
                            print(f"å¤„ç†ç¬¬{chapter_num}ç« æ—¶å‡ºé”™ï¼š{e}")
                            failed_chapters.append(chapter_num)
                
                # é‡Šæ”¾å½“å‰æ‰¹æ¬¡çš„ç« èŠ‚å†…å®¹
                del batch_chapters
                del chapter_data
                
                # å¼ºåˆ¶åƒåœ¾å›æ”¶ä»¥é‡Šæ”¾å†…å­˜
                self._force_garbage_collection()
                print(f"ç¬¬ {i//batch_size + 1} æ‰¹å¤„ç†å®Œæˆï¼Œå·²é‡Šæ”¾å†…å­˜")
            
            print(f"\n--- åˆå§‹ç”Ÿæˆå®Œæˆ ---")
            print(f"æˆåŠŸç”Ÿæˆï¼š{success_count}/{len(chapters)}ä¸ªç« èŠ‚")
            if failed_chapters:
                print(f"å¤±è´¥ç« èŠ‚ï¼š{failed_chapters}")
            
            # éªŒè¯æ‰€æœ‰ç« èŠ‚è´¨é‡
            print(f"\n--- éªŒè¯ç« èŠ‚è´¨é‡ ---")
            all_invalid, length_insufficient, other_invalid = self.validate_existing_chapters(
                output_dir, (1, len(chapters))
            )
            
            # é‡æ–°ç”Ÿæˆæ— æ•ˆç« èŠ‚
            if all_invalid:
                print(f"\n--- é‡æ–°ç”Ÿæˆæ— æ•ˆç« èŠ‚ ---")
                regenerate_success = self.regenerate_invalid_chapters(output_dir, all_invalid)
                
                if regenerate_success:
                    print("\nâœ“ æ‰€æœ‰æ— æ•ˆç« èŠ‚é‡æ–°ç”ŸæˆæˆåŠŸ")
                else:
                    print("\nâš  éƒ¨åˆ†ç« èŠ‚é‡æ–°ç”Ÿæˆå¤±è´¥")
                
                # æœ€ç»ˆéªŒè¯
                print(f"\n--- æœ€ç»ˆéªŒè¯ ---")
                final_invalid, _, _ = self.validate_existing_chapters(
                    output_dir, (1, len(chapters))
                )
                
                if not final_invalid:
                    print("\nğŸ‰ æ‰€æœ‰ç« èŠ‚æœ€ç»ˆéªŒè¯é€šè¿‡ï¼")
                else:
                    print(f"\nâš  ä»æœ‰ {len(final_invalid)} ä¸ªç« èŠ‚å­˜åœ¨é—®é¢˜ï¼š{final_invalid}")
            
            print(f"\n=== è„šæœ¬ç”Ÿæˆå®Œæˆ ===")
            print(f"è¾“å‡ºç›®å½•ï¼š{output_dir}")
            print(f"ç”Ÿæˆç« èŠ‚æ•°ï¼š{len(chapters)}")
            
            return True
            
        except Exception as e:
            print(f"ç”Ÿæˆè„šæœ¬æ—¶å‡ºé”™ï¼š{e}")
            return False

def main():
    """
    ä¸»å‡½æ•°ï¼Œå¤„ç†å‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(description='å¢å¼ºç‰ˆè„šæœ¬ç”Ÿæˆå™¨ - æ”¯æŒç« èŠ‚è´¨é‡éªŒè¯å’Œé‡æ–°ç”Ÿæˆ')
    parser.add_argument('novel_file', help='å°è¯´æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šè‡ªåŠ¨æ ¹æ®å°è¯´æ–‡ä»¶è·¯å¾„ç¡®å®šï¼Œå¦‚data/004/xxx.txtåˆ™è¾“å‡ºåˆ°data/004ï¼‰')
    parser.add_argument('--chapters', '-c', type=int, default=50, help='ç›®æ ‡ç« èŠ‚æ•°é‡ï¼ˆé»˜è®¤ï¼š50ï¼‰')
    parser.add_argument('--limit', '-l', type=int, help='é™åˆ¶ç”Ÿæˆå‰Nä¸ªç« èŠ‚')
    parser.add_argument('--workers', '-w', type=int, default=5, help='æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š5ï¼‰')
    parser.add_argument('--validate-only', action='store_true', help='ä»…éªŒè¯ç°æœ‰ç« èŠ‚ï¼Œä¸ç”Ÿæˆæ–°å†…å®¹')
    parser.add_argument('--regenerate', action='store_true', help='é‡æ–°ç”Ÿæˆæ— æ•ˆç« èŠ‚')
    parser.add_argument('--min-length', type=int, default=1300, help='è§£è¯´æ–‡æ¡ˆæœ€å°é•¿åº¦ï¼ˆé»˜è®¤ï¼š1300ï¼‰')
    parser.add_argument('--max-length', type=int, default=1700, help='è§£è¯´æ–‡æ¡ˆæœ€å¤§é•¿åº¦ï¼ˆé»˜è®¤ï¼š1700ï¼‰')
    parser.add_argument('--max-retries', type=int, default=3, help='æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ï¼š3ï¼‰')
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œåˆ™æ ¹æ®å°è¯´æ–‡ä»¶è·¯å¾„è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºç›®å½•
    if not args.output:
        # æ£€æŸ¥å°è¯´æ–‡ä»¶æ˜¯å¦åœ¨dataç›®å½•ä¸‹çš„å­ç›®å½•ä¸­
        novel_path = os.path.abspath(args.novel_file)
        if 'data/' in novel_path:
            # æå–dataç›®å½•ä¸‹çš„å­ç›®å½•ä½œä¸ºè¾“å‡ºç›®å½•
            data_index = novel_path.find('data/')
            relative_path = novel_path[data_index:]
            # è·å–data/xxxéƒ¨åˆ†
            path_parts = relative_path.split(os.sep)
            if len(path_parts) >= 2:  # data/xxx
                args.output = os.path.join(path_parts[0], path_parts[1])
            else:
                # å¦‚æœä¸åœ¨dataå­ç›®å½•ä¸­ï¼Œä½¿ç”¨å°è¯´æ–‡ä»¶å
                novel_filename = os.path.splitext(os.path.basename(args.novel_file))[0]
                args.output = f'data/{novel_filename}'
        else:
            # å¦‚æœä¸åœ¨dataç›®å½•ä¸­ï¼Œä½¿ç”¨å°è¯´æ–‡ä»¶å
            novel_filename = os.path.splitext(os.path.basename(args.novel_file))[0]
            args.output = f'data/{novel_filename}'
    
    try:
        # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
        generator = ScriptGeneratorV2()
        
        # æ›´æ–°éªŒè¯é…ç½®
        generator.validation_config.update({
            'min_length': args.min_length,
            'max_length': args.max_length,
            'max_retries': args.max_retries
        })
        
        if args.validate_only:
            # ä»…éªŒè¯æ¨¡å¼
            print("=== éªŒè¯æ¨¡å¼ ===")
            chapter_range = None
            if args.limit:
                chapter_range = (1, args.limit)
                print(f"éªŒè¯èŒƒå›´ï¼šå‰{args.limit}ä¸ªç« èŠ‚")
            
            all_invalid, length_insufficient, other_invalid = generator.validate_existing_chapters(
                args.output, chapter_range
            )
            
            if args.regenerate and all_invalid:
                print("\n=== é‡æ–°ç”Ÿæˆæ¨¡å¼ ===")
                generator.regenerate_invalid_chapters(args.output, all_invalid)
        
        else:
            # ç”Ÿæˆæ¨¡å¼
            success = generator.generate_script_from_novel(
                args.novel_file,
                args.output,
                args.chapters,
                args.workers,
                args.limit
            )
            
            if success:
                print("\nğŸ‰ è„šæœ¬ç”ŸæˆæˆåŠŸï¼")
            else:
                print("\nâŒ è„šæœ¬ç”Ÿæˆå¤±è´¥ï¼")
                sys.exit(1)
    
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™ï¼š{e}")
        sys.exit(1)

if __name__ == "__main__":
    main()